{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised ML Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('9_5day_resampled.csv')#using 100% labelled resampled data\n",
    "X=df.iloc[:,:-1]\n",
    "y=df.iloc[:,-1]\n",
    "Xtrain,Xval,ytrain,yval=train_test_split(X,y,random_state=0,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "train0=time.time()\n",
    "clf=RandomForestClassifier().fit(Xtrain,ytrain)\n",
    "train1=time.time()\n",
    "print('train-time: '+str(train1-train0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train accuracy : \"+str(clf.score(Xtrain,ytrain))) #train accuracy\n",
    "test0=time.time()\n",
    "print(\"Test accuracy : \"+str(clf.score(Xval,yval)))# test accuracy\n",
    "test1=time.time()\n",
    "print('test-time: '+str(test1-test0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(Xval)\n",
    "print('weighted F1 Score : ' + str(f1_score(y_pred,yval,average = 'weighted')))\n",
    "print('weighted Precision : ' + str(precision_score(y_pred,yval,average = 'weighted',zero_division=1)))\n",
    "print('weighted Recall : ' + str(recall_score(y_pred,yval,average = 'weighted',zero_division=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(Xval)\n",
    "print('macro F1 Score : ' + str(f1_score(y_pred,yval,average = 'macro')))\n",
    "print('macro Precision : ' + str(precision_score(y_pred,yval,average = 'macro',zero_division=1)))\n",
    "print('macro Recall : ' + str(recall_score(y_pred,yval,average = 'macro',zero_division=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "train0=time.time()\n",
    "clf=DecisionTreeClassifier().fit(Xtrain,ytrain)\n",
    "train1=time.time()\n",
    "print('train-time: '+str(train1-train0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train accuracy : \"+str(clf.score(Xtrain,ytrain))) #train accuracy\n",
    "test0=time.time()\n",
    "print(\"Test accuracy : \"+str(clf.score(Xval,yval)))# test accuracy\n",
    "test1=time.time()\n",
    "print('test-time: '+str(test1-test0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(Xval)\n",
    "print('weighted F1 Score : ' + str(f1_score(y_pred,yval,average = 'weighted')))\n",
    "print('weighted Precision : ' + str(precision_score(y_pred,yval,average = 'weighted',zero_division=1)))\n",
    "print('weighted Recall : ' + str(recall_score(y_pred,yval,average = 'weighted',zero_division=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(Xval)\n",
    "print('macro F1 Score : ' + str(f1_score(y_pred,yval,average = 'macro')))\n",
    "print('macro Precision : ' + str(precision_score(y_pred,yval,average = 'macro',zero_division=1)))\n",
    "print('macro Recall : ' + str(recall_score(y_pred,yval,average = 'macro',zero_division=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train0=time.time()\n",
    "clf = OneVsRestClassifier(XGBClassifier(verbosity=0)).fit(Xtrain, ytrain)\n",
    "train1=time.time()\n",
    "print('train-time: '+str(train1-train0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(Xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(Xval,yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test0=time.time()\n",
    "z= clf.score(Xval,yval)\n",
    "test1=time.time()\n",
    "print('test-time: '+str(test1-test0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(Xval)\n",
    "print('weighted F1 Score : ' + str(f1_score(y_pred,yval,average = 'weighted')))\n",
    "print('weighted Precision : ' + str(precision_score(y_pred,yval,average = 'weighted',zero_division=1)))\n",
    "print('weighted Recall : ' + str(recall_score(y_pred,yval,average = 'weighted',zero_division=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred=clf.predict(Xval)\n",
    "print('macro F1 Score : ' + str(f1_score(y_pred,yval,average = 'macro')))\n",
    "print('macro Precision : ' + str(precision_score(y_pred,yval,average = 'macro',zero_division=1)))\n",
    "print('macro Recall : ' + str(recall_score(y_pred,yval,average = 'macro',zero_division=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(Xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F1 Scores : ' )\n",
    "pd.DataFrame(f1_score(y_pred,yval,labels=yval.unique(),average = None),columns=['F1-score'],index=yval.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Precision Scores : ' )\n",
    "pd.DataFrame(precision_score(y_pred,yval,labels=yval.unique(),average = None),columns=['Precision-score'],index=yval.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Recall Scores : ' )\n",
    "pd.DataFrame(recall_score(y_pred,yval,labels=yval.unique(),average = None),columns=['recall-score'],index=yval.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix with 10 chosen well-known classes\n",
    "Classes : AMAZON, FACEBOOK, GMAIL, GOOGLE, HTTP, OFFICE_365, SKYPE, TWITTER, WHATSAPP, YOUTUBE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "apps=['AMAZON','FACEBOOK','GMAIL','GOOGLE','HTTP','OFFICE_365','SKYPE','TWITTER','WHATSAPP','YOUTUBE']#reporting for these well-known Apps\n",
    "yval[yval.isin(apps)]\n",
    "cm=confusion_matrix(yval[yval.isin(apps)],y_pred[yval.isin(apps)],labels=yval[yval.isin(apps)].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_pc=pd.DataFrame((cm.T/np.sum(cm,axis=1)).T,columns=yval[yval.isin(apps)].unique(),index=yval[yval.isin(apps)].unique())\n",
    "cm_pc=cm_pc.replace(np.nan,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(15,10))\n",
    "df_cm=pd.DataFrame(cm,columns=yval[yval.isin(apps)].unique(),index=yval[yval.isin(apps)].unique())\n",
    "sns.set(font_scale=1.1)\n",
    "sns.heatmap(cm_pc, annot=True,fmt='.1%',cmap=sns.color_palette(\"Reds\",150)) # font size\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "train0=time.time()\n",
    "clf=SVC(random_state=0,kernel='rbf').fit(Xtrain,ytrain)\n",
    "train1=time.time()\n",
    "print('train-time: '+str(train1-train0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train accuracy : \"+str(clf.score(Xtrain,ytrain))) #train accuracy\n",
    "test0=time.time()\n",
    "print(\"Test accuracy : \"+str(clf.score(Xval,yval)))# test accuracy\n",
    "test1=time.time()\n",
    "print('test-time: '+str(test1-test0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(Xval)\n",
    "print('weighted F1 Score : ' + str(f1_score(y_pred,yval,average = 'weighted')))\n",
    "print('weighted Precision : ' + str(precision_score(y_pred,yval,average = 'weighted',zero_division=1)))\n",
    "print('weighted Recall : ' + str(recall_score(y_pred,yval,average = 'weighted',zero_division=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(Xval)\n",
    "print('macro F1 Score : ' + str(f1_score(y_pred,yval,average = 'macro')))\n",
    "print('macro Precision : ' + str(precision_score(y_pred,yval,average = 'macro',zero_division=1)))\n",
    "print('macro Recall : ' + str(recall_score(y_pred,yval,average = 'macro',zero_division=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "Xtrain=scaler.fit_transform(Xtrain)\n",
    "Xval=scaler.transform(Xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train0=time.time()\n",
    "clf = MLPClassifier(hidden_layer_sizes=(100,200,400,50),random_state=0, max_iter=700,learning_rate_init=0.001).fit(Xtrain, ytrain)\n",
    "train1=time.time()\n",
    "print('train-time: '+str(train1-train0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train accuracy : \"+str(clf.score(Xtrain,ytrain))) #train accuracy\n",
    "test0=time.time()\n",
    "print(\"Test accuracy : \"+str(clf.score(Xval,yval)))# test accuracy\n",
    "test1=time.time()\n",
    "print('test-time: '+str(test1-test0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(Xval)\n",
    "print('weighted F1 Score : ' + str(f1_score(y_pred,yval,average = 'weighted')))\n",
    "print('weighted Precision : ' + str(precision_score(y_pred,yval,average = 'weighted',zero_division=1)))\n",
    "print('weighted Recall : ' + str(recall_score(y_pred,yval,average = 'weighted',zero_division=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(Xval)\n",
    "print('macro F1 Score : ' + str(f1_score(y_pred,yval,average = 'macro')))\n",
    "print('macro Precision : ' + str(precision_score(y_pred,yval,average = 'macro',zero_division=1)))\n",
    "print('macro Recall : ' + str(recall_score(y_pred,yval,average = 'macro',zero_division=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
